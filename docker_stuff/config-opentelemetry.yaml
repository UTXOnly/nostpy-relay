receivers:
  otlp:
    protocols:
      http:
        endpoint: 0.0.0.0:4318
      grpc:
        endpoint: 0.0.0.0:4317

  docker_stats:
    endpoint: unix:///var/run/docker.sock
    metrics:
      container.network.io.usage.rx_packets:
        enabled: true
      container.network.io.usage.tx_packets:
        enabled: true
      container.cpu.usage.system:
        enabled: true
      container.memory.rss:
        enabled: true
      container.blockio.io_serviced_recursive:
        enabled: true
      container.uptime:
        enabled: true
      container.memory.hierarchical_memory_limit:
        enabled: true

  hostmetrics:
    collection_interval: 10s
    scrapers:
      paging:
        metrics:
          system.paging.utilization:
            enabled: true
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
          system.cpu.physical.count:
            enabled: true
          system.cpu.logical.count:
            enabled: true
          system.cpu.frequency:
            enabled: true
      disk:
      filesystem:
        metrics:
          system.filesystem.utilization:
            enabled: true
      load:
      memory:
      network:
      processes:

processors:
  batch:
    timeout: 5s                   # Reduce the timeout to process batches more frequently
    send_batch_size: 512          # Increase the batch size to send more data at once
    send_batch_max_size: 4096     # Allow larger maximum batch size             # Increase the queue size to handle more pending data

  memory_limiter:
    check_interval: 1s
    limit_mib: 4000
    spike_limit_mib: 800

  resourcedetection:
    detectors: [env, ec2, system]
    system:
      resource_attributes:
        os.description:
          enabled: true
        host.arch:
          enabled: true
        host.cpu.vendor.id:
          enabled: true
        host.cpu.family:
          enabled: true
        host.cpu.model.id:
          enabled: true
        host.cpu.model.name:
          enabled: true
        host.cpu.stepping:
          enabled: true
        host.cpu.cache.l2.size:
          enabled: true

  attributes:
    actions:
      - key: deployment.environment
        value: nostpy-otel
        action: upsert
      - key: dd.env
        value: nostpy-otel
        action: upsert

connectors:
  datadog/connector:

exporters:
  datadog/exporter:
    api:
      site: datadoghq.com
      key: ${DD_API_KEY}
    traces:
      trace_buffer: 500

  otlp:
    endpoint: "http://opentelemetry-collector:4317"
    tls:
      insecure: true  # Only use insecure for testing purposes, remove in production

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch, resourcedetection, attributes]
      exporters: [datadog/connector, datadog/exporter]
    metrics:
      receivers: [datadog/connector, otlp, hostmetrics, docker_stats]
      processors: [memory_limiter, batch, resourcedetection, attributes]
      exporters: [datadog/exporter]
    logs:
      receivers: [otlp]
      processors: [memory_limiter, batch, resourcedetection, attributes]
      exporters: [ datadog/exporter, otlp]

  telemetry:
    logs:
      level: "debug"
